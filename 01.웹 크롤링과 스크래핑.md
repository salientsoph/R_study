- library(): 현재 R에 설치된 패키지 리스트를 나타냄
- R에는 엑셀 문서를 읽어오는 api가 없으므로, -> library(readxl) 을 사용
- 



# 정적 스크래핑

1. 웹 스크래핑(web scraping) : 

   - 끌어와서 컨텐츠 내용 중 __일부분만 뽑아오는 것__ (태그의 속성들 등)

   - 웹 사이트 상에서 원하는 부분에 위치한 정보를 컴퓨터로 하여금 자동으로 추출하여 수집하는 기술

2. 웹 크롤링(web crawling) : 

   - __끌어오는 것__
   - 자동화 봇(bot)인 웹 크롤러가 정해진 규칙에 따라 복수 개의 웹 페이지를 브라우징 하는 행위

![스크래핑](C:\Users\salient\Pictures\스크래핑.png)



![스크래핑2](C:\Users\salient\Pictures\스크래핑2.png)









## 1. 네이버 영화 사이트 댓글정보 스크래핑

네이버 영화 사이트의 데이터 중 __영화제목, 평점, 리뷰__만을 추출하여 CSV 파일의 정형화된 형식으로 저장

![네이버영화](C:\Users\salient\Pictures\네이버영화.png)

1. 스크래핑하려는 웹페이지의 URL 구조와 문서 구조를 파악해야 한다.

- 영화 제목으로 찾아본다 -> Id 속성을 본다 -> class 속성을 본다(다른 것도 같은 값이 있을 수 있어서 id속성보단 추천되지 않음)

- URL 구조 : [http](http://movie.naver.com/movie/point/af/list.nhn?page=1)[://movie.naver.com/movie/point/af/list.nhn?page=](http://movie.naver.com/movie/point/af/list.nhn?page=1)[1](http://movie.naver.com/movie/point/af/list.nhn?page=1)

- Em태그(emphasize(강조)) : div 태그에 자식태그 em 을 찾기

- css 선택자 

  - 리뷰만 골라내는 건 없음 
  - __태그__까지는 접근 가능
  - 몇 번째 컨텐츠를 꺼내겠다~ 는 기능 없음

  -> 따라서 xpath로 꺼낸다

- 문서 구조(접근하고자 할 때) 

   영화 제목 class=”.movie” (css 선택자는 . 를 붙임)

   영화 평점 class=”.title em” (title이라는 속성에 em 자식)

   영화 리뷰 xpath= ”//*[@id=＇old_content＇]/table/tbody/tr/td[2]/text()”

- css: copy > copy selector

- xpath: copy > xpath selector

- 함수

  __read_html(대상(url), encoding)__: url을 끌어오는 함수  

  - encoding의 default: UTF-8 (동일시 생략 가능)

  __html_nodes(대상, css)__: 태그 선택하는 함수

  __html_text(대상)__: 출력해주는 함수

  __html_attr(대상, "속성")__: 속성을 출력해주는 함수





[단일 페이지 스크래핑]

```R
install.packages(“rvest”); 
library(rvest)

# 이전의 설정값이 있을까봐 초기화
text<- NULL; title<-NULL; point<-NULL, review<-NULL; page=NULL
url<- "http://movie.naver.com/movie/point/af/list.nhn?page=1"

# read_html(): url을 끌어오는 함수
text <- read_html(url,  encoding="CP949"); text   # euc-kr == cp949

# 영화제목
# html_nodes(대상, css): 태그 선택하는 함수()
# html_text(): 출력해주는 함수
nodes <- html_nodes(text, ".movie")
title <- html_text(nodes); title

# 영화평점
nodes <- html_nodes(text, ".title em")
point <- html_text(nodes); point

# 영화리뷰 
nodes <- html_nodes(text, xpath="//*[@id='old_content']/table/tbody/tr/td[2]/text()")
# trim=TRUE: text area (앞뒤에 있는 blank, 공백, tab, 개행문자 등)을 다 제거해줌
nodes <- html_text(nodes, trim=TRUE)
review <- nodes[nchar(nodes) > 0] # nodes들중 0보다 큰 것들만 남김(내용 있는 것만 남김)
review
page <- data.frame(title, point, review)
# csv로 데이터 새로 저장
write.csv(page, "movie_reviews.csv")

```









copy > copy selector

//*[@id="old_content"]/table/tbody/tr[1]/td[2]/a[1]

#old_content > table > tbody > tr:nth-child(1) > td.title > a.movie.color_b

#old_content > table > tbody > tr:nth-child(2) > td.title > a.movie.color_b

#old_content > table > tbody > tr:nth-child(3) > td.title > a.movie.color_b



#old_content > table > tbody > tr:nth-child(3) > td.title > a.movie.color_b

----------------------------------------------------> .movie



#old_content > table > tbody > tr:nth-child(1) > td.title > div > em

----------------------------------------------------> td.title em



copy > copy xpath

//*[@id="old_content"]/table/tbody/tr[1]/td[2]/text()

//*[@id="old_content"]/table/tbody/tr[2]/td[2]/text()

----------------------------------------------------> //*[@id="old_content"]/table/tbody/tr/td[2]/text()