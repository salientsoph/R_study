- library(): 현재 R에 설치된 패키지 리스트를 나타냄
- R에는 엑셀 문서를 읽어오는 api가 없으므로, -> library(readxl) 을 사용
- 



# 정적 스크래핑

1. 웹 스크래핑(web scraping) : 

   - 끌어와서 컨텐츠 내용 중 __일부분만 뽑아오는 것__ (태그의 속성들 등)

   - 웹 사이트 상에서 원하는 부분에 위치한 정보를 컴퓨터로 하여금 자동으로 추출하여 수집하는 기술

2. 웹 크롤링(web crawling) : 

   - __끌어오는 것__
   - 자동화 봇(bot)인 웹 크롤러가 정해진 규칙에 따라 복수 개의 웹 페이지를 브라우징 하는 행위

![스크래핑](C:\Users\salient\Pictures\스크래핑.png)



![스크래핑2](C:\Users\salient\Pictures\스크래핑2.png)









## 1. 네이버 영화 사이트 댓글정보 스크래핑

네이버 영화 사이트의 데이터 중 __영화제목, 평점, 리뷰__만을 추출하여 CSV 파일의 정형화된 형식으로 저장

![네이버영화](C:\Users\salient\Pictures\네이버영화.png)

1. 스크래핑하려는 웹페이지의 URL 구조와 문서 구조를 파악해야 한다.

- 영화 제목으로 찾아본다 -> Id 속성을 본다 -> class 속성을 본다(다른 것도 같은 값이 있을 수 있어서 id속성보단 추천되지 않음)

- URL 구조 : [http](http://movie.naver.com/movie/point/af/list.nhn?page=1)[://movie.naver.com/movie/point/af/list.nhn?page=](http://movie.naver.com/movie/point/af/list.nhn?page=1)[1](http://movie.naver.com/movie/point/af/list.nhn?page=1)

- Em태그(emphasize(강조)) : div 태그에 자식태그 em 을 찾기

- css 선택자 

  - 리뷰만 골라내는 건 없음 
  - __태그__까지는 접근 가능
  - 몇 번째 컨텐츠를 꺼내겠다~ 는 기능 없음

  -> 따라서 xpath로 꺼낸다

- 문서 구조(접근하고자 할 때) 

   영화 제목 class=”.movie” (css 선택자는 . 를 붙임)

   영화 평점 class=”.title em” (title이라는 속성에 em 자식)

   영화 리뷰 xpath= ”//*[@id=＇old_content＇]/table/tbody/tr/td[2]/text()”

- css: copy > copy selector

- xpath: copy > xpath selector

- 함수

  __read_html(대상(url), encoding)__: url을 끌어오는 함수  

  - encoding의 default: UTF-8 (동일시 생략 가능)

  __html_nodes(대상, "css주소")__: 태그 선택하는 함수 

  - 2번째 인자 default: css 이므로 xpath를 줄 시에는 xpath="주소"  로 준다 

  __html_text(대상)__: 출력해주는 함수
  
  __html_attr(대상, "속성")__: 속성을 출력해주는 함수

- XPath 설명:   https://ko.wikipedia.org/wiki/XPath





[단일 페이지 스크래핑]

```R
install.packages(“rvest”); 
library(rvest)

# 이전의 설정값이 있을까봐 초기화
text<- NULL; title<-NULL; point<-NULL, review<-NULL; page=NULL
url<- "http://movie.naver.com/movie/point/af/list.nhn?page=1"

# read_html(): url을 끌어오는 함수
text <- read_html(url,  encoding="CP949"); text   # euc-kr == cp949

# 영화제목
# html_nodes(대상, css): 태그 선택하는 함수()
# html_text(): 출력해주는 함수
nodes <- html_nodes(text, ".movie")
title <- html_text(nodes); title

# 영화평점
nodes <- html_nodes(text, ".title em")
point <- html_text(nodes); point

# 영화리뷰 
nodes <- html_nodes(text, xpath="//*[@id='old_content']/table/tbody/tr/td[2]/text()")
# trim=TRUE: text area (앞뒤에 있는 blank, 공백, tab, 개행문자 등)을 다 제거해줌
nodes <- html_text(nodes, trim=TRUE)
review <- nodes[nchar(nodes) > 0] # nodes들중 0보다 큰 것들만 남김(내용 있는 것만 남김)
review
page <- data.frame(title, point, review)
# csv로 데이터 새로 저장
write.csv(page, "movie_reviews.csv")

```









copy > copy selector

//*[@id="old_content"]/table/tbody/tr[1]/td[2]/a[1]

#old_content > table > tbody > tr:nth-child(1) > td.title > a.movie.color_b

#old_content > table > tbody > tr:nth-child(2) > td.title > a.movie.color_b

#old_content > table > tbody > tr:nth-child(3) > td.title > a.movie.color_b



#old_content > table > tbody > tr:nth-child(3) > td.title > a.movie.color_b

----------------------------------------------------> .movie



#old_content > table > tbody > tr:nth-child(1) > td.title > div > em

----------------------------------------------------> td.title em



copy > copy xpath

//*[@id="old_content"]/table/tbody/tr[1]/td[2]/text()

//*[@id="old_content"]/table/tbody/tr[2]/td[2]/text()

----------------------------------------------------> //*[@id="old_content"]/table/tbody/tr/td[2]/text()













rvest 패키지: 









xml 패키지: 

끌어오고자 하는 웹페이지가 공공db를 끌어오거나, sns api를 이용해 끌어온다거나 등은 xml과 json이 많다. 





//*[@id="main-top01-scroll-in"]/div[2]/div/h4/a





httr 패키지: get방식, post 방식 요청/ 받아오고나선 rvest 등 사용/ 스크래핑 보다는 크롤링에 특화됨

post 방식 요청

get 방식 요청(로그인, 회원가입)







[open API를 활용한 공공DB와 SNS 데이터 수집]

정적 웹페이지 수집과 사용이 거의 비슷



open API: 

1) 함수, 클래스, ... : API는 application programming interface(어플 개발시 가져다 쓸 수 있는, 미리 만들어져있는 함수나 클래스)

여기서 open --> free 무료로 사용하는 API

2) URL 문자열(web 세상): 필요한 데이터를 요청하고 받아갈 수 있게 지원하는 URL 문자열

- 인증키, Query 문자열 등을 필요로 함

- 요청 헤더에 규격정보를 제공해야 할 수도 있음

  



공공DB: 정부에서 지원하는 데이터베이스(서울시 빅데이터 등)

SNS: 페이스북, 트위터, 네이버, 다음 등에 올라와있는 글에 대한 수집



네이버

https://developers.naver.com/docs/search/blog 에서 내용 검토

![네이버1](C:\Users\salient\Pictures\네이버1.png)



![네이버2](C:\Users\salient\Pictures\네이버2.png)

![네이버3](C:\Users\salient\Pictures\네이버3.png)







Response [https://openapi.naver.com/v1/search/blog.xml?query=%EB%B4%84&display=100]
  Date: 2020-09-17 02:10
  Status: 200
  Content-Type: application/xml; charset=UTF-8
  Size: 66.6 kB
<BINARY BODY>



->  "응답헤더"

Date: 2020-09-17 02:10
Status: 200
Content-Type: application/xml; charset=UTF-8
Size: 66.6 kB







# 동적 스크래핑

동적 웹페이지 수집



javascript에 의한 동적 태그, ajax에 의한 동적 태그 -> 셀레늄이라는 프로그램으로 끌어와야.

"브라우저가 렌더링": 태그에 맞춰 그 도큐먼트를 보여줌, js 코드를 실행시켜서 컨텐츠를 동적으로 만들어낸 것 등



js를 안쓰고 html, css만 -> 동일

js를 사용, 일부 컨텐츠를 동적으로 -> 서버로 부터 보내진 소스정보랑, 렌더링된 소스 내용이 다름 





자바스크립트를 혼용해서 쓰는 홈페이지가 훨씬 더 많다. 

다음의 경우에는 웹 페이지의 내용이 동적으로 생성되는 경우에는 지금까지의 방법으로 스크래핑 할 수 없다.

-사용자의 선택과 같은 이벤트에 의해서 자바스크립트의 수행 결과로 컨텐츠를 생성한다. 

-페이지의 랜더링을 끝낸 후에 Ajax 기술을 이용하여 서버로 부터 컨텐트의 일부를 전송받아 동적으로 구성한다.

이러한 경우에는 Selenium 을 사용하면 제어되는 브라우저에 페이지를 랜더링 해놓고 랜더링된 결과에서 컨텐츠를 읽어올 수 있다. 뿐만 아니라 컨텐츠내에서 클릭이벤트를 발생할 수도 있으며 로그인과 같은 데이터를 입력하는 것도 가능하다.







## 정규 표현식 활용

정규 표현식 regular expression, 간단히 regexp 또는 regex, rational expression)(https://ko.wikipedia.org/wiki/정규_표현식#cite_note-Lawson2003 또는  정규식은 특정한 규칙을 가진 문자열의 집합을 표현하는 데 사용하는 [형식 언어]이다.



?: 양의 크기

""*"": 0번 이상, 별표는 0번 이상의 발생을 의미한다. 이를테면 `ab*c`는 "ac", "abc", "abbc", "abbbc" 등을 일치시킨다.

+: 1번 이상,  덧셈 기호는 1번 이상의 발생을 의미한다. 이를테면 `ab+c`는 "abc", "abbc", "abbbc" 등을 일치시키지만 "ac"는 일치시키지 않는다.





[^ ]: not

| 메타문자 |        기능         |                             설명                             |
| :------: | :-----------------: | :----------------------------------------------------------: |
|    .     |        문자         | 1개의 문자와 일치한다. 단일행 모드에서는 [새줄 문자](https://ko.wikipedia.org/wiki/새줄_문자)를 제외한다. |
|   [ ]    |     문자 클래스     | "["과 "]" 사이의 문자 중 하나를 선택한다. "¦"를 여러 개 쓴 것과 같은 의미이다. 예를 들면 [abc]d는 ad, bd, cd를 뜻한다. 또한, "-" 기호와 함께 쓰면 범위를 지정할 수 있다. "[a-z]"는 a부터 z까지 중 하나, "[1-9]"는 1부터 9까지 중의 하나를 의미한다. |
|   [^ ]   |        부정         | 문자 클래스 안의 문자를 제외한 나머지를 선택한다. 예를 들면 [^abc]d는 ad, bd, cd는 포함하지 않고 ed, fd 등을 포함한다. [^a-z]는 알파벳 소문자로 시작하지 않는 모든 문자를 의미한다. |
|    ^     |        처음         |               문자열이나 행의 처음을 의미한다.               |
|    $     |         끝          |                문자열이나 행의 끝을 의미한다.                |
|   ( )    |       하위식        | 여러 식을 하나로 묶을 수 있다. "abc¦adc"와 "a(b¦d)c"는 같은 의미를 가진다. |
|    \n    | 일치하는 n번째 패턴 | 일치하는 패턴들 중 n번째를 선택하며, 여기에서 n은 1에서 9 중 하나가 올 수 있다. |
|    *     |      0회 이상       | 0개 이상의 문자를 포함한다. "a*b"는 "b", "ab", "aab", "aaab"를 포함한다. |
|  {m, n}  |  m회 이상 n회 이하  | "a{1,3}b"는 "ab", "aab", "aaab"를 포함하지만, "b"나 "aaaab"는 포함하지 않는다. |